{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86820e77666d8529",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Stage 3\n",
    "## 1. Running Spark Apps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:00.035789Z",
     "start_time": "2024-05-10T17:13:47.392148Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add here your team number teamx\n",
    "team = \"team31\"\n",
    "\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"{} - spark ML\".format(team)) \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse) \\\n",
    "    .config(\"spark.sql.avro.compression.codec\", \"snappy\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0baa5f6394fa59c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:13.657491Z",
     "start_time": "2024-05-10T17:14:05.616266Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             root_db|\n",
      "|     team0_projectdb|\n",
      "|team12_hive_proje...|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team17_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "|    team21_projectdb|\n",
      "|    team22_projectdb|\n",
      "|    team23_projectdb|\n",
      "|    team24_projectdb|\n",
      "|    team25_projectdb|\n",
      "|    team26_projectdb|\n",
      "|    team27_projectdb|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "++\n",
      "||\n",
      "++\n",
      "++\n",
      "+----------------+--------------------+-----------+\n",
      "|       namespace|           tableName|isTemporary|\n",
      "+----------------+--------------------+-----------+\n",
      "|team31_projectdb|          checkpoint|      false|\n",
      "|team31_projectdb|current_market_va...|      false|\n",
      "|team31_projectdb|current_owners_pa...|      false|\n",
      "|team31_projectdb|market_values_dis...|      false|\n",
      "|team31_projectdb|  mint_holding_times|      false|\n",
      "|team31_projectdb|               mints|      false|\n",
      "|team31_projectdb|                nfts|      false|\n",
      "|team31_projectdb|ownership_transit...|      false|\n",
      "|team31_projectdb|          q1_results|      false|\n",
      "|team31_projectdb|          q2_results|      false|\n",
      "|team31_projectdb|          q3_results|      false|\n",
      "|team31_projectdb|          q4_results|      false|\n",
      "|team31_projectdb|          q5_results|      false|\n",
      "|team31_projectdb|transfer_holding_...|      false|\n",
      "|team31_projectdb|transfer_statisti...|      false|\n",
      "|team31_projectdb|transfer_values_q...|      false|\n",
      "|team31_projectdb|transfer_values_q...|      false|\n",
      "|team31_projectdb|transfer_values_q...|      false|\n",
      "|team31_projectdb|           transfers|      false|\n",
      "|team31_projectdb|     transfers_mints|      false|\n",
      "+----------------+--------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "db_name = f\"{team}_projectdb\"\n",
    "\n",
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "spark.sql(f\"USE {db_name}\").show()\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d443746d5cdcae3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. Read Hive tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34732b110a600ed6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:15.830465Z",
     "start_time": "2024-05-10T17:14:13.659259Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table(name='checkpoint', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='current_market_values', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='current_owners_partitioned', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='market_values_distribution', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='mint_holding_times', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='mints', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='nfts', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='ownership_transitions', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='q1_results', database='team31_projectdb', description=None, tableType='MANAGED', isTemporary=False), Table(name='q2_results', database='team31_projectdb', description=None, tableType='MANAGED', isTemporary=False), Table(name='q3_results', database='team31_projectdb', description=None, tableType='MANAGED', isTemporary=False), Table(name='q4_results', database='team31_projectdb', description=None, tableType='MANAGED', isTemporary=False), Table(name='q5_results', database='team31_projectdb', description=None, tableType='MANAGED', isTemporary=False), Table(name='transfer_holding_times', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='transfer_statistics_by_address', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='transfer_values_quantile_10_distribution_per_address', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='transfer_values_quantile_25_distribution_per_address', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='transfer_values_quartile_10_distribution_per_address', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='transfers', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False), Table(name='transfers_mints', database='team31_projectdb', description=None, tableType='EXTERNAL', isTemporary=False)]\n"
     ]
    }
   ],
   "source": [
    "print(spark.catalog.listTables(db_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595f483f13d0ac57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:21.974373Z",
     "start_time": "2024-05-10T17:14:15.831918Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- token_id: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- nft_address: string (nullable = true)\n",
      " |-- transaction_value: float (nullable = true)\n",
      "+--------+----------+--------------------+-----------------+\n",
      "|token_id| timestamp|         nft_address|transaction_value|\n",
      "+--------+----------+--------------------+-----------------+\n",
      "|    2970|1630824455|0x8Ca5209d8CCe34b...|              0.0|\n",
      "|    1115|1628128263|0xd448E6CCA10ff5d...|     9.9999998E16|\n",
      "|  661252|1630824788|0x1dfe7Ca09e99d10...|              0.0|\n",
      "|   90489|1630824861|0x1dfe7Ca09e99d10...|              0.0|\n",
      "|     952|1629043069|0x8184a482A5038B1...|    1.28000003E18|\n",
      "+--------+----------+--------------------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "631816"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mints = spark.read.format(\"avro\").table(f\"{db_name}.mints\").select(\"token_id\", \"timestamp\",\n",
    "                                                                   \"nft_address\",\n",
    "                                                                   \"transaction_value\")\n",
    "mints.printSchema()\n",
    "mints.show(5)\n",
    "mints.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473419cb240970c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:26.300108Z",
     "start_time": "2024-05-10T17:14:21.975875Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- token_id: string (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      " |-- transaction_value: float (nullable = true)\n",
      "\n",
      "+--------+----------+-----------------+\n",
      "|token_id| timestamp|transaction_value|\n",
      "+--------+----------+-----------------+\n",
      "|    7731|1630202720|     5.8999997E18|\n",
      "|93000048|1624715050|     9.9999998E16|\n",
      "|    7263|1632165910|    1.49999994E18|\n",
      "|    5913|1629735476|              0.0|\n",
      "|     169|1624231533|    1.29000004E17|\n",
      "+--------+----------+-----------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "380676"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfers = spark.read.format(\"avro\").table(f\"{db_name}.transfers\").select(\"token_id\", \"timestamp\",\n",
    "                                                                           \"transaction_value\")\n",
    "transfers.printSchema()\n",
    "transfers.show(5)\n",
    "transfers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641c1a49e4e917b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:27.151903Z",
     "start_time": "2024-05-10T17:14:26.301540Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- address: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "+--------------------+------------------+\n",
      "|             address|              name|\n",
      "+--------------------+------------------+\n",
      "|0x385eDC73Dd943b6...|    Silly Old Bear|\n",
      "|0xf6680e700394e7f...|        Astraglade|\n",
      "|0xcEb2EA7E904c74A...|                  |\n",
      "|0xfE303C462407Bf6...|     Image By Andy|\n",
      "|0x5e302f9EbA7B0E8...|PFP Ability Scores|\n",
      "+--------------------+------------------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9388"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfts = spark.read.format(\"avro\").table(f\"{db_name}.nfts\").select(\"address\", \"name\")\n",
    "nfts.printSchema()\n",
    "nfts.show(5)\n",
    "nfts.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6094c0915dcdb2ac",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. ML Modeling\n",
    "### 3.1 Feature Selection & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e011f0bb2cb2893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:31.737169Z",
     "start_time": "2024-05-10T17:14:27.153487Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------+--------------+---------------+--------------+\n",
      "|         nft_address|num_tokens|      avg_mint_price|max_mint_price|min_mint_price|first_mint_date|last_mint_date|\n",
      "+--------------------+----------+--------------------+--------------+--------------+---------------+--------------+\n",
      "|0xe5fAB3f3e33762E...|        54|6.296296467910808E15| 1.00000003E16|           0.0|     1630518131|    1630543090|\n",
      "|0x90Ff5796b1e7711...|       132|                 0.0|           0.0|           0.0|     1628258725|    1632571347|\n",
      "|0xD9a3fCa910f76C8...|        94|1.332978718157547...|  5.9999999E17|           0.0|     1623417307|    1624391310|\n",
      "|0x7a7Fd1034Cb577b...|        59|                 0.0|           0.0|           0.0|     1629146697|    1632413521|\n",
      "|0x1Fa27357E1838B0...|         9|2.222222187348332...|  9.9999998E17|  9.9999998E16|     1631148203|    1632338670|\n",
      "+--------------------+----------+--------------------+--------------+--------------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "contract_stats = (\n",
    "    mints\n",
    "    .groupBy(\"nft_address\")\n",
    "    .agg(\n",
    "        F.countDistinct(\"token_id\").alias(\"num_tokens\"),\n",
    "        F.avg(\"transaction_value\").alias(\"avg_mint_price\"),\n",
    "        F.max(\"transaction_value\").alias(\"max_mint_price\"),\n",
    "        F.min(\"transaction_value\").alias(\"min_mint_price\"),\n",
    "        F.min(\"timestamp\").alias(\"first_mint_date\"),\n",
    "        F.max(\"timestamp\").alias(\"last_mint_date\"),\n",
    "    )\n",
    ")\n",
    "contract_stats.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29ace0e3d2f3f713",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:36.845650Z",
     "start_time": "2024-05-10T17:14:31.738862Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------+------------+------------+------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|     token_id|last_tx_value|tx_count|min_tx_value|max_tx_value|first_tx_timestamp|last_tx_timestamp|      min_n_tx_value|      max_n_tx_value|first_n_tx_timestamp|\n",
      "+-------------+-------------+--------+------------+------------+------------------+-----------------+--------------------+--------------------+--------------------+\n",
      "|1000000000004|       9.9E18|       1|         0.0|         0.0|        1621456719|       1621456719|                 0.0|                 0.0|          1621456719|\n",
      "|1000000000012|          0.0|       3|         0.0|         0.0|        1625827928|       1626100381|                 0.0|                 0.0|          1625827928|\n",
      "|    100000048|          0.0|       0|        null|        null|              null|             null|                null|                null|                null|\n",
      "|     10000006|4.99999992E17|       0|        null|        null|              null|             null|                null|                null|                null|\n",
      "|    100000078| 7.9999999E17|       1|      1.8E19|      1.8E19|        1632123394|       1632123394|1.800000040471625...|1.800000040471625...|          1632123394|\n",
      "+-------------+-------------+--------+------------+------------+------------------+-----------------+--------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "\n",
    "\n",
    "def _get_last_n_txs(arr, n):\n",
    "    return arr[-n:]\n",
    "\n",
    "\n",
    "get_last_n_txs = F.udf(_get_last_n_txs, T.ArrayType(T.StructType([\n",
    "    T.StructField(\"timestamp\", T.LongType()),\n",
    "    T.StructField(\"transaction_value\", T.DoubleType()),\n",
    "])))\n",
    "\n",
    "LAST_N = 10\n",
    "\n",
    "nft_history = (\n",
    "    transfers\n",
    "    .groupBy(\"token_id\")\n",
    "    .agg(\n",
    "        F.sort_array(F.collect_list(F.struct(\"timestamp\", \"transaction_value\"))).alias(\"tx_data\"),\n",
    "    )\n",
    "    .withColumn(\"tx_data_except_last\", F.expr(\"slice(tx_data, 1, size(tx_data) - 1)\"))\n",
    "    .withColumn(\"last_tx\", F.element_at(\"tx_data\", -1))\n",
    "    .withColumn(\"last_tx_value\", F.col(\"last_tx.transaction_value\"))\n",
    "    .drop(\"last_tx\")\n",
    "    .drop(\"tx_data\")\n",
    "    # Overall stats (excluding last tx)\n",
    "    .withColumn(\"tx_count\", F.size(\"tx_data_except_last\"))\n",
    "    .withColumn(\"min_tx_value\", F.array_min(\"tx_data_except_last.transaction_value\"))\n",
    "    .withColumn(\"max_tx_value\", F.array_max(\"tx_data_except_last.transaction_value\"))\n",
    "    .withColumn(\"first_tx_timestamp\", F.element_at(\"tx_data_except_last.timestamp\", 1))\n",
    "    .withColumn(\"last_tx_timestamp\", F.element_at(\"tx_data_except_last.timestamp\", -1))\n",
    "    .withColumn(\"last_n_transactions\", get_last_n_txs(\"tx_data_except_last\", F.lit(LAST_N)))\n",
    "    .drop(\"tx_data_except_last\")\n",
    "    # Stats for the last N transactions\n",
    "    .withColumn(\"min_n_tx_value\", F.array_min(\"last_n_transactions.transaction_value\"))\n",
    "    .withColumn(\"max_n_tx_value\", F.array_max(\"last_n_transactions.transaction_value\"))\n",
    "    .withColumn(\"first_n_tx_timestamp\", F.element_at(\"last_n_transactions.timestamp\", 1))\n",
    "    .drop(\"last_n_transactions\")\n",
    ")\n",
    "nft_history.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a81defac4e98db67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:40.362505Z",
     "start_time": "2024-05-10T17:14:36.847170Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631816\n"
     ]
    }
   ],
   "source": [
    "features = (\n",
    "    mints.selectExpr(\"nft_address\", \"token_id\", \"timestamp as mint_timestamp\",\n",
    "                     \"transaction_value as mint_tx_value\")\n",
    "    .join(contract_stats, on=\"nft_address\", how=\"left\")\n",
    "    .join(nft_history, on=\"token_id\", how=\"left\")\n",
    "    .join(nfts, on=(mints.nft_address == nfts.address), how=\"left\")\n",
    "    .drop(\"nft_address\", \"address\")\n",
    ")\n",
    "print(features.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f247155d5a1b76ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:48.872167Z",
     "start_time": "2024-05-10T17:14:40.364021Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------+-------------+----------+--------------------+--------------+--------------+---------------+--------------+-------------+--------+------------+------------+------------------+-----------------+--------------+--------------------+--------------------+-------------+\n",
      "|token_id|mint_timestamp|mint_tx_value|num_tokens|      avg_mint_price|max_mint_price|min_mint_price|first_mint_date|last_mint_date|last_tx_value|tx_count|min_tx_value|max_tx_value|first_tx_timestamp|last_tx_timestamp|min_n_tx_value|      max_n_tx_value|first_n_tx_timestamp|         name|\n",
      "+--------+--------------+-------------+----------+--------------------+--------------+--------------+---------------+--------------+-------------+--------+------------+------------+------------------+-----------------+--------------+--------------------+--------------------+-------------+\n",
      "|  112994|    1630773556|          0.0|     12287|                 0.0|           0.0|           0.0|     1630769995|    1632578269|         null|    null|        null|        null|              null|             null|          null|                null|                null|    More Loot|\n",
      "|    1371|    1628287231|2.99999995E17|      1025|7.164585205993205...| 2.99999988E18|           0.0|     1628287013|    1628394248|       2.3E17|     423|         0.0|      9.9E18|        1617973492|       1632567035|           0.0|9.600000261661655E17|          1632479273|Cute Pig Club|\n",
      "|   77875|    1630773376|          0.0|     12287|                 0.0|           0.0|           0.0|     1630769995|    1632578269|          0.0|       4|         0.0|         0.0|        1625989788|       1630580489|           0.0|                 0.0|          1625989788|    More Loot|\n",
      "|     316|    1630133950| 9.9000001E16|        74|9.900000119514726...|  9.9000001E16|  9.9000001E16|     1630132861|    1630134575|1.00000003E16|     609|         0.0|      2.5E19|        1617296090|       1632572490|           0.0|7.000000233744629...|          1632526621|       Ribonz|\n",
      "|     172|    1629783883|       7.0E16|        22|1.272727293751459...| 3.50000012E17|           0.0|     1629759875|    1629787453| 3.9900001E16|     669|         0.0|      2.0E19|        1617453154|       1632575268|           0.0|6.942000308184678...|          1632517736|     Hog Gang|\n",
      "+--------+--------------+-------------+----------+--------------------+--------------+--------------+---------------+--------------+-------------+--------+------------+------------+------------------+-----------------+--------------+--------------------+--------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "features.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1748dc7304ea74a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:48.884771Z",
     "start_time": "2024-05-10T17:14:48.874138Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = features.withColumnRenamed(\"last_tx_value\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f38392079b6c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:48.907388Z",
     "start_time": "2024-05-10T17:14:48.886269Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_features = features.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8479e6fc30c6d2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:54.828923Z",
     "start_time": "2024-05-10T17:14:48.908884Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570887"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_features.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299f855af3b56fa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.2 Feature Extraction Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c3b9abd767121e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:54.842168Z",
     "start_time": "2024-05-10T17:14:54.830980Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_cols = [\"mint_timestamp\", \"first_mint_date\", \"last_mint_date\", \"first_tx_timestamp\", \"last_tx_timestamp\", \"first_n_tx_timestamp\"]\n",
    "text_cols = [\"name\"]\n",
    "numerical_cols = [\"num_tokens\", \"avg_mint_price\", \"max_mint_price\", \"min_mint_price\", \"tx_count\", \"min_tx_value\", \"max_tx_value\", \"min_n_tx_value\", \"max_n_tx_value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5319e784f826f499",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:58.267787Z",
     "start_time": "2024-05-10T17:14:54.844034Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-------------+----------+--------------------+--------------+--------------+-------------------+-------------------+-------------+--------+------------+-------------+-------------------+-------------------+--------------+--------------------+--------------------+-----------------+\n",
      "|token_id|     mint_timestamp|mint_tx_value|num_tokens|      avg_mint_price|max_mint_price|min_mint_price|    first_mint_date|     last_mint_date|        label|tx_count|min_tx_value| max_tx_value| first_tx_timestamp|  last_tx_timestamp|min_n_tx_value|      max_n_tx_value|first_n_tx_timestamp|             name|\n",
      "+--------+-------------------+-------------+----------+--------------------+--------------+--------------+-------------------+-------------------+-------------+--------+------------+-------------+-------------------+-------------------+--------------+--------------------+--------------------+-----------------+\n",
      "|   10351|2021-08-20 21:56:27|       7.5E19|      1011|2.569362058904216...|        7.5E19|           0.0|2021-08-14 01:00:33|2021-09-23 17:05:56|5.39999985E17|      39|         0.0|1.85399994E18|2021-05-20 16:54:16|2021-09-25 00:22:23|           0.0|1.287999944052965...| 2021-09-06 10:10:33|    Floyd's World|\n",
      "|   21331|2021-09-17 12:54:50|          0.0|       981|4.925586189853352E16| 1.68000003E18|           0.0|2021-09-16 05:05:23|2021-09-25 06:59:10|          0.0|       7|         0.0|       4.6E17|2021-04-09 01:31:09|2021-09-08 13:22:17|           0.0|4.599999996530524...| 2021-04-09 01:31:09| MoonCatLootprint|\n",
      "|   10351|2021-08-17 22:43:01|          0.0|      1215|                 0.0|           0.0|           0.0|2021-08-04 11:23:46|2021-08-18 00:47:10|5.39999985E17|      39|         0.0|1.85399994E18|2021-05-20 16:54:16|2021-09-25 00:22:23|           0.0|1.287999944052965...| 2021-09-06 10:10:33|      NFT Dungeon|\n",
      "|   10351|2021-07-28 00:37:54|3.50000012E17|      1063|3.675493912576648...|  7.0000001E18|           0.0|2021-07-26 13:14:11|2021-07-28 00:38:02|5.39999985E17|      39|         0.0|1.85399994E18|2021-05-20 16:54:16|2021-09-25 00:22:23|           0.0|1.287999944052965...| 2021-09-06 10:10:33|      Stoner Cats|\n",
      "|   10351|2021-09-22 08:08:18|1.80000001E17|      1279|3.173073110006606...| 3.72120007E18| 2.24999995E15|2021-09-19 15:00:25|2021-09-22 12:55:45|5.39999985E17|      39|         0.0|1.85399994E18|2021-05-20 16:54:16|2021-09-25 00:22:23|           0.0|1.287999944052965...| 2021-09-06 10:10:33|LordsOfLightPacks|\n",
      "+--------+-------------------+-------------+----------+--------------------+--------------+--------------+-------------------+-------------------+-------------+--------+------------+-------------+-------------------+-------------------+--------------+--------------------+--------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "filtered_features_with_dt = filtered_features.selectExpr(\n",
    "    *(f\"from_unixtime({col}) as {col}\" if col in date_cols else col for col in\n",
    "      filtered_features.columns))\n",
    "filtered_features_with_dt.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c2abbaeb3409516",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:58.404050Z",
     "start_time": "2024-05-10T17:14:58.269715Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, Word2Vec, VectorAssembler, StandardScaler\n",
    "\n",
    "# Collection name encoding\n",
    "tokenizer = Tokenizer(inputCol=text_cols[0], outputCol=text_cols[0] + \"_tokens\")\n",
    "word2vec = Word2Vec(vectorSize=16, minCount=1, inputCol=tokenizer.getOutputCol(),\n",
    "                    outputCol=text_cols[0] + \"_w2v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec9f2806b146a42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:58.415309Z",
     "start_time": "2024-05-10T17:14:58.405673Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml import Transformer\n",
    "from pyspark.ml.param.shared import HasInputCol, HasOutputCol, Param, Params, TypeConverters\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "\n",
    "\n",
    "# Date encoding\n",
    "class DateCyclicalEncodingTransformer(Transformer, HasInputCol, HasOutputCol, DefaultParamsReadable,\n",
    "                                      DefaultParamsWritable):\n",
    "    input_col = Param(Params._dummy(), \"input_col\", \"input column name.\",\n",
    "                      typeConverter=TypeConverters.toString)\n",
    "    output_col = Param(Params._dummy(), \"output_col\", \"output column name.\",\n",
    "                       typeConverter=TypeConverters.toString)\n",
    "\n",
    "    @keyword_only\n",
    "    def __init__(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "        super(DateCyclicalEncodingTransformer, self).__init__()\n",
    "        self._setDefault(input_col=None, output_col=None)\n",
    "        kwargs = self._input_kwargs\n",
    "        self.set_params(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def set_params(self, input_col: str = \"input\", output_col: str = \"output\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        self._set(**kwargs)\n",
    "\n",
    "    def get_input_col(self):\n",
    "        return self.getOrDefault(self.input_col)\n",
    "\n",
    "    def get_output_col(self):\n",
    "        return self.getOrDefault(self.output_col)\n",
    "\n",
    "    def _transform(self, df):\n",
    "        input_col = self.get_input_col()\n",
    "        output_col = self.get_output_col()\n",
    "        df = df.withColumn(output_col + \"_year\", F.year(F.col(input_col)))\n",
    "        for col, val_count in (\n",
    "                (\"month\", 12), (\"day\", 31), (\"hour\", 24), (\"minute\", 60), (\"second\", 60)):\n",
    "            df = (\n",
    "                df\n",
    "                .withColumn(output_col + f\"_{col}_sin\",\n",
    "                            F.sin(2 * math.pi * F.expr(f\"{col}({input_col})\") / val_count))\n",
    "                .withColumn(\n",
    "                    output_col + f\"_{col}_cos\",\n",
    "                    F.cos(2 * math.pi * F.expr(f\"{col}({input_col})\") / val_count)\n",
    "                )\n",
    "            )\n",
    "        return df\n",
    "\n",
    "    def get_all_column_names(self):\n",
    "        output_col = self.get_output_col()\n",
    "        return [output_col + \"_year\"] + [output_col + f\"_{col}_sin\" for col in\n",
    "                                         (\"month\", \"day\", \"hour\", \"minute\", \"second\")] + [\n",
    "            output_col + f\"_{col}_cos\" for col in (\"month\", \"day\", \"hour\", \"minute\", \"second\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c61991463deb6d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:58.447456Z",
     "start_time": "2024-05-10T17:14:58.416689Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_transformers = [DateCyclicalEncodingTransformer(input_col=col, output_col=\"encoded_\" + col) for\n",
    "                     col in date_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83e3cb6b3cd1728c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:58.498273Z",
     "start_time": "2024-05-10T17:14:58.448998Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_to_assemble = [text_cols[0] + \"_w2v\"] + sum(\n",
    "    (dt.get_all_column_names() for dt in date_transformers), []) + numerical_cols\n",
    "\n",
    "assembler = VectorAssembler(inputCols=cols_to_assemble, outputCol=\"raw_features\")\n",
    "scaler = StandardScaler(inputCol=\"raw_features\", outputCol=\"features\", withMean=True, withStd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ce59dd64acb6706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:14:58.513498Z",
     "start_time": "2024-05-10T17:14:58.499462Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, word2vec] + date_transformers + [assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51b043db454a1eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:15:19.451565Z",
     "start_time": "2024-05-10T17:14:58.514947Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipeline_model = pipeline.fit(filtered_features_with_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff1b23c11dee2d5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:15:24.446241Z",
     "start_time": "2024-05-10T17:15:19.452992Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|            features|        label|\n",
      "+--------------------+-------------+\n",
      "|[0.78744739591365...|5.39999985E17|\n",
      "|[-0.1059161603900...|          0.0|\n",
      "|[0.46321664661966...|5.39999985E17|\n",
      "|[1.70527180772611...|5.39999985E17|\n",
      "|[-0.0636783197343...|5.39999985E17|\n",
      "+--------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "transformed_features = pipeline_model.transform(filtered_features_with_dt).select(\"features\",\n",
    "                                                                                  \"label\")\n",
    "transformed_features.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2468218a1ee5c04",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.3 Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9c828cf79b4b2ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:15:24.504985Z",
     "start_time": "2024-05-10T17:15:24.447811Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_data, test_data) = transformed_features.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1abc9195a476bfee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:15:54.410135Z",
     "start_time": "2024-05-10T17:15:24.506961Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"json\") \\\n",
    "    .save(\"project/data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91d03e6ebf8581c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:16:16.837070Z",
     "start_time": "2024-05-10T17:15:54.411523Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"json\") \\\n",
    "    .save(\"project/data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a346eac30a612b36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:16:21.059344Z",
     "start_time": "2024-05-10T17:16:16.838714Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat project/data/train/*.json > ../data/train.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8193dbafafd6c54e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:16:24.049155Z",
     "start_time": "2024-05-10T17:16:21.061031Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat project/data/test/*.json > ../data/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5da6f79334f6b5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:16:56.475213Z",
     "start_time": "2024-05-10T17:16:24.050959Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gzip -c -9 ../data/train.json > ../data/train.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9260c8da8238ada4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T17:17:11.631962Z",
     "start_time": "2024-05-10T17:16:56.476958Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!gzip -c -9 ../data/test.json > ../data/test.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6bcfb51fdd690",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.4 First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b450a422b67c3abe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:23:44.634915Z",
     "start_time": "2024-05-10T15:23:38.132047Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "to_vector = F.udf(lambda vs: Vectors.dense(vs), VectorUDT())\n",
    "\n",
    "train_data = spark.read.json(\"project/data/train\").selectExpr(\"features.values as features\",\n",
    "                                                              \"label\").withColumn(\"features\",\n",
    "                                                                                  to_vector(\n",
    "                                                                                      \"features\"))\n",
    "test_data = spark.read.json(\"project/data/test\").selectExpr(\"features.values as features\",\n",
    "                                                            \"label\").withColumn(\"features\",\n",
    "                                                                                to_vector(\n",
    "                                                                                    \"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fb25df147631779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:23:44.640223Z",
     "start_time": "2024-05-10T15:23:44.636548Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- label: double (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632d45f48b4c693c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:23:56.404850Z",
     "start_time": "2024-05-10T15:23:44.642048Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f489f32c42a3dc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:23:56.412508Z",
     "start_time": "2024-05-10T15:23:56.406577Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations: 64\n",
      "RMSE: 1626087951446105856.00\n",
      "R2 score: 0.01945\n"
     ]
    }
   ],
   "source": [
    "training_summary = lr_model.summary\n",
    "print(\"Number of iterations:\", training_summary.totalIterations)\n",
    "print(f\"RMSE: {training_summary.rootMeanSquaredError:.2f}\")\n",
    "print(f\"R2 score: {training_summary.r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dd999bdcff0f298b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:23:56.543759Z",
     "start_time": "2024-05-10T15:23:56.413859Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+\n",
      "|            features|        label|          prediction|\n",
      "+--------------------+-------------+--------------------+\n",
      "|[-4.7039155659731...|1.29999995E16|2.517081314455933...|\n",
      "|[-4.7039155659731...|          0.0|1.089464638468397...|\n",
      "|[-4.7039155659731...|5.50000009E17|6.157348480292416E16|\n",
      "|[-4.7039155659731...| 8.0000002E16|8.944542372326313...|\n",
      "|[-4.7039155659731...| 5.8799999E17|5.286698603387879...|\n",
      "+--------------------+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e01a06626c926ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:23:56.558236Z",
     "start_time": "2024-05-10T15:23:56.545583Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "rmse_evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                     metricName=\"rmse\")\n",
    "r2_evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca14ce3bca4913c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:24:01.757542Z",
     "start_time": "2024-05-10T15:23:56.559958Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1713754268755438592.00\n",
      "R2 score: 0.02456\n"
     ]
    }
   ],
   "source": [
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "r2_score = r2_evaluator.evaluate(predictions)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R2 score: {r2_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6eaa700c019a2a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:19.055005Z",
     "start_time": "2024-05-10T15:24:23.145022Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegressionModel: uid=LinearRegression_4ff1acd7785e, numFeatures=91"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "grid = ParamGridBuilder()\n",
    "grid = grid.addGrid(\n",
    "    lr_model.aggregationDepth, [2, 3, 4]) \\\n",
    "    .addGrid(lr_model.regParam, np.logspace(1e-3, 1e-1)\n",
    "             ) \\\n",
    "    .build()\n",
    "\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=grid,\n",
    "                    evaluator=r2_evaluator,\n",
    "                    parallelism=5,\n",
    "                    numFolds=3)\n",
    "\n",
    "cvModel = cv.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c93ecb501031dcd9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:19.064126Z",
     "start_time": "2024-05-10T15:27:19.056526Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='LinearRegression_4ff1acd7785e', name='fitIntercept', doc='whether to fit an intercept term.'): True,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='featuresCol', doc='features column name.'): 'features',\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='epsilon', doc='The shape parameter to control the amount of robustness. Must be > 1.0. Only valid when loss is huber'): 1.35,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='aggregationDepth', doc='suggested depth for treeAggregate (>= 2).'): 3,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='loss', doc='The loss function to be optimized. Supported options: squaredError, huber.'): 'squaredError',\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='maxIter', doc='max number of iterations (>= 0).'): 100,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='regParam', doc='regularization parameter (>= 0).'): 1.0747467053333597,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='tol', doc='the convergence tolerance for iterative algorithms (>= 0).'): 1e-06,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='labelCol', doc='label column name.'): 'label',\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='standardization', doc='whether to standardize the training features before fitting the model.'): True,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='maxBlockSizeInMB', doc='maximum memory in MB for stacking input data into blocks. Data is stacked within partitions. If more than remaining data size in a partition then it is adjusted to the data size. Default 0.0 represents choosing optimal value, depends on specific algorithm. Must be >= 0.'): 0.0,\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
      " Param(parent='LinearRegression_4ff1acd7785e', name='solver', doc='The solver algorithm for optimization. Supported options: auto, normal, l-bfgs.'): 'auto'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(bestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f40efeb4b6cdc535",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:19.154820Z",
     "start_time": "2024-05-10T15:27:19.065464Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+\n",
      "|            features|        label|          prediction|\n",
      "+--------------------+-------------+--------------------+\n",
      "|[-4.7039155659731...|1.29999995E16|2.516882016039310...|\n",
      "|[-4.7039155659731...|          0.0|1.089342662935894...|\n",
      "|[-4.7039155659731...|5.50000009E17|6.155812403158675...|\n",
      "|[-4.7039155659731...| 8.0000002E16|8.942848096075625...|\n",
      "|[-4.7039155659731...| 5.8799999E17|5.286557720543809...|\n",
      "+--------------------+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "best_predictions = bestModel.transform(test_data)\n",
    "best_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4177d805e665a33d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:22.552195Z",
     "start_time": "2024-05-10T15:27:19.156240Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 1713754246732851200.00\n",
      "Best R2 score: 0.02456\n"
     ]
    }
   ],
   "source": [
    "best_rmse = rmse_evaluator.evaluate(best_predictions)\n",
    "best_r2_score = r2_evaluator.evaluate(best_predictions)\n",
    "print(f\"Best RMSE: {best_rmse:.2f}\")\n",
    "print(f\"Best R2 score: {best_r2_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b3d2e9ab004fa42f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:22.557329Z",
     "start_time": "2024-05-10T15:27:22.553726Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 difference: 0.0000000251\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 difference: {best_r2_score - r2_score:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4268388954babd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:22.571473Z",
     "start_time": "2024-05-10T15:27:22.558970Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE difference: 22022587392.00\n",
      "RMSE improvement: 0.0000012850%\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE difference: {rmse - best_rmse:.2f}\")\n",
    "print(f\"RMSE improvement: {(rmse - best_rmse) / rmse:.10%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "535597537cdebc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:46:25.535097Z",
     "start_time": "2024-05-10T15:46:25.530891Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE, Gwei: 1713754246.73285\n",
      "Best RMSE, ETH 1.71375\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best RMSE, Gwei: {best_rmse / 10 ** 9:.5f}\")\n",
    "print(f\"Best RMSE, ETH {best_rmse / 10 ** 18:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "79f5b87b4e83cd70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:23.834769Z",
     "start_time": "2024-05-10T15:27:22.573112Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1 = bestModel\n",
    "model1.write().overwrite().save(\"project/models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51e62a32c1c7d455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:25.665239Z",
     "start_time": "2024-05-10T15:27:23.836322Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -get project/models/model1 ../models/model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e4b917c6a89b1df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:37.689256Z",
     "start_time": "2024-05-10T15:27:25.666912Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_predictions.select(\"label\", \"prediction\") \\\n",
    "    .coalesce(1) \\\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(\"project/output/model1_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7a24c333bf07fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:27:39.511153Z",
     "start_time": "2024-05-10T15:27:37.690715Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat project/output/model1_predictions.csv/*.csv > ../output/model1_predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e2090bb21f7b15",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.5 Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "53bc4a8f5575e799",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:28:02.864004Z",
     "start_time": "2024-05-10T15:27:39.512704Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(seed=42)\n",
    "\n",
    "gbt_model = gbt.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d5a0dfd90201da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:28:03.053772Z",
     "start_time": "2024-05-10T15:28:02.865509Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+\n",
      "|            features|        label|          prediction|\n",
      "+--------------------+-------------+--------------------+\n",
      "|[-4.7039155659731...|1.29999995E16|1.441254833912304...|\n",
      "|[-4.7039155659731...|          0.0|8.441977145012555...|\n",
      "|[-4.7039155659731...|5.50000009E17|1.445230285815225...|\n",
      "|[-4.7039155659731...| 8.0000002E16|1.444734375480371...|\n",
      "|[-4.7039155659731...| 5.8799999E17|3.863333462341892...|\n",
      "+--------------------+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "predictions = gbt_model.transform(test_data)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e3bfab2d2bc8fab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:28:06.264493Z",
     "start_time": "2024-05-10T15:28:03.056965Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 863532489246270464.00\n",
      "R2 score: 0.75234\n"
     ]
    }
   ],
   "source": [
    "rmse = rmse_evaluator.evaluate(predictions)\n",
    "r2_score = r2_evaluator.evaluate(predictions)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R2 score: {r2_score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a93cd0ff740bb70f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:14.824947Z",
     "start_time": "2024-05-10T15:28:06.266023Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTRegressionModel: uid=GBTRegressor_0a672806dfda, numTrees=20, numFeatures=91"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "grid = ParamGridBuilder()\n",
    "grid = (grid.addGrid(gbt_model.maxDepth, [2, 5, 10, 15])\n",
    "        .addGrid(gbt_model.maxBins, [32, 128])\n",
    "        .build())\n",
    "\n",
    "cv = CrossValidator(estimator=gbt,\n",
    "                    estimatorParamMaps=grid,\n",
    "                    evaluator=r2_evaluator,\n",
    "                    parallelism=5,\n",
    "                    numFolds=3)\n",
    "\n",
    "cvModel = cv.fit(train_data)\n",
    "bestModel = cvModel.bestModel\n",
    "bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9240db04b2a458f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:14.834970Z",
     "start_time": "2024-05-10T15:45:14.826493Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='GBTRegressor_0a672806dfda', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'all',\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='validationTol', doc='Threshold for stopping early when fit with validation is used. If the error rate on the validation input changes by less than the validationTol, then learning will stop early (before `maxIter`). This parameter is ignored when fit without validation is used.'): 0.01,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '',\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 128,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='subsamplingRate', doc='Fraction of the training data used for learning each decision tree, in range (0, 1].'): 1.0,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='maxIter', doc='max number of iterations (>= 0).'): 20,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='seed', doc='random seed.'): 42,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='featuresCol', doc='features column name.'): 'features',\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: variance'): 'variance',\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='labelCol', doc='label column name.'): 'label',\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='stepSize', doc='Step size (a.k.a. learning rate) in interval (0, 1] for shrinking the contribution of each estimator.'): 0.1,\n",
      " Param(parent='GBTRegressor_0a672806dfda', name='lossType', doc='Loss function which GBT tries to minimize (case-insensitive). Supported options: squared, absolute'): 'squared'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(bestModel.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b605935c6b240b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:15.001678Z",
     "start_time": "2024-05-10T15:45:14.836208Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+\n",
      "|            features|        label|          prediction|\n",
      "+--------------------+-------------+--------------------+\n",
      "|[-4.7039155659731...|1.29999995E16|1.592359448321518...|\n",
      "|[-4.7039155659731...|          0.0|1.365887221229401...|\n",
      "|[-4.7039155659731...|5.50000009E17|1.332288089284610...|\n",
      "|[-4.7039155659731...| 8.0000002E16|2.203297352529219...|\n",
      "|[-4.7039155659731...| 5.8799999E17|3.056335138725716...|\n",
      "+--------------------+-------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "best_predictions = bestModel.transform(test_data)\n",
    "best_predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9a89cd10e1f12bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:18.793424Z",
     "start_time": "2024-05-10T15:45:15.003033Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 831145378236056576.00\n",
      "Best R2 score: 0.77057\n"
     ]
    }
   ],
   "source": [
    "best_rmse_2 = rmse_evaluator.evaluate(best_predictions)\n",
    "best_r2_score_2 = r2_evaluator.evaluate(best_predictions)\n",
    "print(f\"Best RMSE: {best_rmse_2:.2f}\")\n",
    "print(f\"Best R2 score: {best_r2_score_2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "57e9e5c6aa328456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:18.797883Z",
     "start_time": "2024-05-10T15:45:18.794856Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 difference: 0.0182289766\n",
      "R2 improvement: 2.42298%\n"
     ]
    }
   ],
   "source": [
    "print(f\"R2 difference: {best_r2_score_2 - r2_score:.10f}\")\n",
    "print(f\"R2 improvement: {(best_r2_score_2 - r2_score) / r2_score:.5%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8bedef229a3970f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:18.815706Z",
     "start_time": "2024-05-10T15:45:18.799301Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE difference: 32387111010213888.00\n",
      "RMSE improvement: 3.7505376362%\n"
     ]
    }
   ],
   "source": [
    "print(f\"RMSE difference: {rmse - best_rmse_2:.2f}\")\n",
    "print(f\"RMSE improvement: {(rmse - best_rmse_2) / rmse:.10%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4feeb18938a7069",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:39.338195Z",
     "start_time": "2024-05-10T15:45:39.323588Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE, Gwei: 831145378.23606\n",
      "Best RMSE, ETH 0.83115\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best RMSE, Gwei: {best_rmse_2 / 10 ** 9:.5f}\")\n",
    "print(f\"Best RMSE, ETH {best_rmse_2 / 10 ** 18:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e3de52f5d6790ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:21.009010Z",
     "start_time": "2024-05-10T15:45:18.817293Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = bestModel\n",
    "model2.write().overwrite().save(\"project/models/model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fcb20da2b5426d7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:23.022379Z",
     "start_time": "2024-05-10T15:45:21.010571Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -get project/models/model2 ../models/model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cad9591d38c36b82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:37.423829Z",
     "start_time": "2024-05-10T15:45:23.024151Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_predictions.select(\"label\", \"prediction\")\\\n",
    "    .coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .save(\"project/output/model2_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "127358f870a73a79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:45:39.298299Z",
     "start_time": "2024-05-10T15:45:37.426507Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat project/output/model2_predictions.csv/*.csv > ../output/model2_predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5326ae1d02f98efe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.6 Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f13cab423c2e9337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:47:03.042827Z",
     "start_time": "2024-05-10T15:47:01.938360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model1_predictions = spark.read.csv(\"project/output/model1_predictions.csv\", header=True, inferSchema=True)\n",
    "model2_predictions = spark.read.csv(\"project/output/model2_predictions.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55eaef42ae508bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:47:03.864848Z",
     "start_time": "2024-05-10T15:47:03.044406Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_rmse = rmse_evaluator.evaluate(model1_predictions)\n",
    "best_rmse_2 = rmse_evaluator.evaluate(model2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7f3c27670d03593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:47:04.712744Z",
     "start_time": "2024-05-10T15:47:03.866629Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_r2_score = r2_evaluator.evaluate(model1_predictions)\n",
    "best_r2_score_2 = r2_evaluator.evaluate(model2_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "806c5d6edd8533ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:47:08.084069Z",
     "start_time": "2024-05-10T15:47:04.715281Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------+----------------------+--------------------+\n",
      "|model                                                                         |RMSE                  |R2                  |\n",
      "+------------------------------------------------------------------------------+----------------------+--------------------+\n",
      "|LinearRegressionModel: uid=LinearRegression_4ff1acd7785e, numFeatures=91      |1.71375424673285222E18|0.024561243833836843|\n",
      "|GBTRegressionModel: uid=GBTRegressor_0a672806dfda, numTrees=20, numFeatures=91|8.3114537823604992E17 |0.7705664592343757  |\n",
      "+------------------------------------------------------------------------------+----------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "models = [[str(model1), best_rmse, best_r2_score], [str(model2), best_rmse_2, best_r2_score_2]]\n",
    "\n",
    "df = spark.createDataFrame(models, [\"model\", \"RMSE\", \"R2\"])\n",
    "df.show(truncate=False)\n",
    "\n",
    "# Save it to HDFS\n",
    "df.coalesce(1)\\\n",
    "    .write\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .save(\"project/output/evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c4ae08a79685ed2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T15:47:14.550856Z",
     "start_time": "2024-05-10T15:47:12.620644Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -cat project/output/evaluation.csv/*.csv > ../output/evaluation.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
